<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>202412s on 喵ฅ^•ﻌ•^ฅ</title>
    <link>https://ruohai.wang/202412/</link>
    <description>Recent content in 202412s on 喵ฅ^•ﻌ•^ฅ</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Sun, 22 Dec 2024 21:56:12 +0800</lastBuildDate><atom:link href="https://ruohai.wang/202412/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>PVE基础使用：This host key is known by other names的问题处理</title>
      <link>https://ruohai.wang/202412/pve-virt-machine-duplicated-key-fingerprint/</link>
      <pubDate>Sun, 22 Dec 2024 21:56:12 +0800</pubDate>
      
      <guid>https://ruohai.wang/202412/pve-virt-machine-duplicated-key-fingerprint/</guid>
      <description>前言 开篇Tips：本文根据chatgpt的回答进行整理。
问题描述 在pve上使用同一个备份还原出多个虚拟机，然后每个虚拟机都各自生用ssh-keygen -t xxx生成一对密钥，然后用此密钥作为登录凭证进行ssh登录认证时，本地的终端出现以下提示
The authenticity of host &amp;#39;[192.168.1.207]:12345 ([192.168.1.207]:12345)&amp;#39; can&amp;#39;t be established. ED25519 key fingerprint is SHA256:xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx. This host key is known by the following other names/addresses: C:\Users\Ruohai/.ssh/known_hosts:11: [192.168.1.209]:12345 Are you sure you want to continue connecting (yes/no/[fingerprint])? 从提示内容来看，就是用同一个备份还原出的两个虚拟机，虽然各自生成了密钥，但密钥的指纹（fingerprint）相同。
我尝试在两个虚拟机中删除旧ssh-key然后重新生成，但本地终端依旧会出现以上提示。
问题解决 在Proxmox VE（PVE）系统中，当你使用相同的虚拟机备份（即还原同一个虚拟机的镜像）来创建多个虚拟机时，每个虚拟机会有一个相同的SSH密钥对。如果这些虚拟机在同一个网络中并且它们的SSH密钥相同，那么它们的SSH指纹也会相同。当你尝试通过SSH连接到这些虚拟机时，系统会提示“key指纹重复”，因为它发现多个主机具有相同的SSH指纹。
解决方法：清空旧的SSH密钥，强制系统重新生成密钥。
操作：删除/etc/ssh目录下的ssh_host_*_key文件并重启服务。
sudo rm /etc/ssh/ssh_host_* sudo dpkg-reconfigure openssh-server 在执行dpkg-reconfigure命令时，会弹出蓝色窗口进行选择
选择第二项keep the local version currently installed，即保持当前的/etc/sshs/sshd_config配置文件，不要覆盖。
然后系统会重新生成不同加密模式的密钥对，提示信息如下
ruohai@debian:/etc/ssh$ sudo dpkg-reconfigure openssh-server Creating SSH2 RSA key; this may take some time .</description>
    </item>
    
    <item>
      <title>PVE基础使用：创建虚拟机时机型i440fx和q35如何选择</title>
      <link>https://ruohai.wang/202412/pve-i440fx-vs-q35/</link>
      <pubDate>Fri, 20 Dec 2024 01:03:30 +0800</pubDate>
      
      <guid>https://ruohai.wang/202412/pve-i440fx-vs-q35/</guid>
      <description>前言 开篇Tips：本文根据chatgpt的回答进行整理。
正文 在pve系统下创建虚拟机时，有一个机型的选项，默认是i440fx，还有另外一个可选项q35。这两选项有何区别，它俩孰优孰劣，该如何选择呢？
在 Proxmox VE (PVE) 中创建虚拟机时，i440fx和q35是两种不同的虚拟机硬件平台，它们主要的区别在于芯片组的模拟。
i440fx：
老旧平台，类似于早期的 Intel 440FX 芯片组。 它支持较老的硬件和设备模型，兼容性较强，适合运行较旧的操作系统或软件（比如 Windows XP、Windows 7 等）。 适合需要较低兼容性要求的系统。 q35：
较新的平台，模拟的是 Intel 的 Q35 芯片组，支持更多现代特性。 提供更好的硬件虚拟化支持，例如更好的 PCIe 设备支持、SATA 和更高效的内存管理。 支持 UEFI 启动，适合运行现代操作系统，尤其是 Windows 10、Windows 11 或 Linux 现代发行版。 选择哪个？
如果你要运行较旧的操作系统或不需要特殊硬件支持，i440fx 是一个更安全的选择，因为它兼容性更好。 如果你要运行较新的操作系统或需要现代硬件特性（如 PCIe 支持、UEFI 启动等），q35 更适合。 一般来说，现代的虚拟化需求推荐选择 q35，尤其是在需要支持 64 位 UEFI 引导或现代硬件功能时。 结论 默认i440fx适合绝大部分情况，兼容性更好 如果硬件比较新，推荐q35 如果有特殊需求，比如uefi启动（win8之后的windows系统）、硬件直通，选q35 喝杯奶茶 </description>
    </item>
    
    <item>
      <title>使用smartmontools对硬盘进行long test任务显示interrupted的问题处理</title>
      <link>https://ruohai.wang/202412/smartmontools-long-test-interrupted/</link>
      <pubDate>Wed, 18 Dec 2024 23:17:20 +0800</pubDate>
      
      <guid>https://ruohai.wang/202412/smartmontools-long-test-interrupted/</guid>
      <description>前言 开篇Tips：本文根据chatgpt的答案进行整理发布。
问题描述 在debian下使用smartmontools对硬盘进行long test
smartctl -t long /dev/sda 终端会显示smartctl开始在后台对硬盘进行长测试，预计97分钟。
=== START OF OFFLINE IMMEDIATE AND SELF-TEST SECTION === Sending command: &amp;#34;Execute SMART Extended self-test routine immediately in off-line mode&amp;#34;. Drive command &amp;#34;Execute SMART Extended self-test routine immediately in off-line mode&amp;#34; successful. Testing has begun. Please wait 97 minutes for test to complete. Test will complete after Wed Dec 18 16:41:14 2024 UTC Use smartctl -X to abort test. 但实际每次检测了10%以后这个long test任务就中止了，用smart -a可以看到检测记录</description>
    </item>
    
    <item>
      <title>使用smartmontools查看usb外接硬盘时显示Unknown USB bridge的问题处理</title>
      <link>https://ruohai.wang/202412/smartmontools-unknow-usb-bridge/</link>
      <pubDate>Wed, 18 Dec 2024 22:07:59 +0800</pubDate>
      
      <guid>https://ruohai.wang/202412/smartmontools-unknow-usb-bridge/</guid>
      <description>前言 开篇Tips: 本文根据chatgpt的回答进行整理。
问题描述 在debian下用smartmontools工具查看usb外接硬盘的smart信息是，根据经验，敲入以下命令
smartctl -a /dev/sdx 此时会出现错误提示
/dev/sda: Unknown USB bridge [0x152d:0x0578 (0x204)] Please specify device type with the -d option. Use smartctl -h to get a usage summary 问题解决 这个问题通常出现在smartmontools无法自动识别通过USB接口连接的硬盘。USB桥接器的控制器可能与smartctl无法兼容，因此提示&amp;quot;Unknown USB bridge&amp;quot;。为了解决这个问题，你需要手动指定硬盘设备的类型。
你可以通过添加-d选项来强制指定设备类型，具体步骤如下：
通过-d选项指定设备类型：你可以尝试用-d usb来指定USB设备类型。命令如下：
smartctl -d usb -a /dev/sda 尝试不同的设备类型：如果-d usb不工作，可以尝试其他的设备类型。常见的选项包括：
-d sat：适用于SATA硬盘。 -d scsi：适用于SCSI硬盘。 -d ata：适用于传统ATA硬盘。 例如，如果你使用的是SATA硬盘，通过USB桥接，你可以尝试：
smartctl -d sat -a /dev/sda Tips：实测用-d sat可以识别通过usb连接的外接sata硬盘。
喝杯奶茶 </description>
    </item>
    
    <item>
      <title>Debian下Crontab中的Java任务不执行的问题排除</title>
      <link>https://ruohai.wang/202412/crontab-java-not-run/</link>
      <pubDate>Wed, 18 Dec 2024 18:45:56 +0800</pubDate>
      
      <guid>https://ruohai.wang/202412/crontab-java-not-run/</guid>
      <description>前言 开篇Tips：本文根据chatgpt的回答进行整理。
问题描述 使用的azulJDK官方下载的jre17，在debian下解压到自定义目录以后，在~/.bashrc下配置了java的环境变量
export JAVA_HOME=/opt/jre export PATH=$JAVA_HOME/bin:$PATH 执行java -version可以正常输出版本信息。
但是在crontab中配置了定时任务【30 6 * * * java -jar /path/to/my/jarfile.jr】的定时任务不执行。与此对比的是，在另一台debian机器上，直接用apt方式安装default-openjre以后（apt仓库里的jre版本也是17），同样的cron任务可以正确执行。
问题原因 crontab任务没有正确识别这些变量的原因可能是cron执行时使用的是不同的环境，它不会加载~/.bashrc或其他shell配置文件。
说人话就是crontab没有读取到我配置在~/.bashrc中的java环境变量
解决方法 方法一：在 crontab 中显式设置环境变量
在 crontab 中直接设置 JAVA_HOME 和 PATH 环境变量，确保 cron 执行时能够找到 java。
打开 crontab 编辑器：
crontab -e 然后在 crontab 文件中添加环境变量的配置，例如：
# 显式设置环境变量 JAVA_HOME=/opt/jre PATH=$JAVA_HOME/bin:$PATH # 定时任务 30 6 * * * java -jar /path/to/my/jarfile.jar 这样，每次 cron 执行任务时，都会加载这些环境变量。
方法二：在 crontab 中定义完整的 java 路径
如果不想设置环境变量，也可以直接在 crontab 中使用 java 的完整路径。</description>
    </item>
    
    <item>
      <title>在Windows 10 LTSC上安装appxbundle文件</title>
      <link>https://ruohai.wang/202412/windows-ltsc-install-appxbundle/</link>
      <pubDate>Wed, 18 Dec 2024 18:32:37 +0800</pubDate>
      
      <guid>https://ruohai.wang/202412/windows-ltsc-install-appxbundle/</guid>
      <description>前言 开篇tips：本文基于chatgpt的回答进行整理修改。
正文 在 Windows LTSC（长期服务通道）版本上安装 .appxbundle 文件的步骤和其他 Windows 版本类似，可以通过 PowerShell 或者通过双击文件进行安装。以下是详细步骤：
方法 1：使用 PowerShell 安装
在 PowerShell 中输入以下命令来安装 .appxbundle 文件：
Add-AppxPackage -Path &amp;#34;C:\path\to\your\appxbundlefile.appxbundle&amp;#34; 安装过程可能会需要一些时间，完成后你应该能够在开始菜单找到应用程序。
Tips：我用的是这个方法，实测有效。
方法 2：直接通过双击文件安装
找到.appxbundle文件
在文件资源管理器中找到.appxbundle文件，双击.appxbundle文件，Windows 应该会自动开始安装该应用。如果文件关联正确，它会直接启动 Microsoft Store 或应用安装界面，然后按照屏幕上的提示完成安装。
Tips：这个方法在windows 10 ltsc上肯定是行不通的。
喝杯奶茶 </description>
    </item>
    
    <item>
      <title>Windows下将Samba共享映射为本地文件夹</title>
      <link>https://ruohai.wang/202412/windows-mklink-soft-link/</link>
      <pubDate>Wed, 18 Dec 2024 18:12:24 +0800</pubDate>
      
      <guid>https://ruohai.wang/202412/windows-mklink-soft-link/</guid>
      <description>前言 开篇TIPS：本文基于chatgpt内容进行整理。
正文 在Windows上，Samba共享通常会被映射为网络驱动器（如Z盘），而不是本地磁盘。
Windows本身并没有直接提供将Samba共享映射为本地磁盘的功能，因为Samba共享本质上仍然是通过网络协议（如SMB/CIFS）进行访问的。
然而，可以使用一些替代方法实现类似的效果：
方法一：使用符号链接（Symbolic Link）:
你可以在Windows上创建符号链接，将某个目录链接到Samba共享目录。这样，虽然共享仍然通过网络访问，但可以像本地目录一样使用。
在cmd命令行中，使用mklink命令，注意使用管理员权限启动cmd，否则会报权限不足：
mklink /D E:\samba \\192.168.1.111\movie 其中/d或者/D指的是软链接，对应的硬链接参数是/J或者/j。
使用以上命令即可将192.168.1.111服务器上共享的movie目录映射到本地E盘的samba文件夹。
Tips：我用的这个方法，实测有效。缺点是只能映射成一个本地文件夹。
方法二：利用第三方软件（如Rclone、WinFsp等）:
有些第三方工具如Rclone（一个开源工具）允许你将远程共享（包括Samba）挂载为本地磁盘（类似于网络驱动器，但更加灵活）。 使用Rclone时，你可以通过设置挂载命令把Samba共享挂载到Windows的本地磁盘上，表现得更像本地磁盘。 例如：
rclone mount remote:/path/to/share X: --vfs-cache-mode writes 这里的 remote:/path/to/share 代表Samba共享，X: 是你希望它映射为的本地驱动器字母。
喝杯奶茶 </description>
    </item>
    
    <item>
      <title>AI开始替代个人博客</title>
      <link>https://ruohai.wang/202412/ai-starts-replace-blog/</link>
      <pubDate>Tue, 17 Dec 2024 18:14:51 +0800</pubDate>
      
      <guid>https://ruohai.wang/202412/ai-starts-replace-blog/</guid>
      <description>最近俩月开始使用chatgpt和copilot来帮助解决一些日常中我会碰到的问题，大部分是折腾linux时候的一些常见的技术小问题，小部分是比如杭州周边游的推荐、一些头痛脑热生病、心理健康类的问题。
这其中的大部分问题，也就是折腾linux、arm盒子，如果是以前，我在通过搜索引擎找解决方案 + 自己实践解决以后，大概率会根据自己的实际处理过程，花点时间写一篇博客出来做记录。但是自打从【搜索引擎搜解决方案】转向【直接问chatgpt】以后，写篇博客记录一下自己解决问题的过程已经变得没有意义了。
为什么用搜索引擎找解决方案的时候有必要自己写一篇博客做记录？
因为搜索引擎搜出来的内容乱七八糟，质量参差不齐，而且中文互联网上的内容很多都是内容农场抄来抄去，很多不要脸的社区搬了别人的内容以后还加上各种查看限制，比如注册可见、登录可复制、下载附件收费甚至挂马。如果是个人网站，可能域名过期、网站关闭、内容已删除。所以最后在找到真正有用的方案以后，有必要自己做个归纳整理，记录成文，方便自己后期回溯。当然如果能帮到别人就更好了。
但是有了ai以后，用搜索引擎会碰到的问题就完全不存在了，虽然ai给出的答案正确率大概也就80~90%，但是对比搜索引擎里一堆良莠不齐的结果 + 自己一个一个打开查看的体验好太多了。而且ai给出的答案排版也非常的漂亮，比自己辛辛苦苦敲markdown发布的博客在可读性上简直是吊打。
这就导致了大部分的it技术类的博客已经完全没有必要记录了，直接问ai即可，也省去了自己敲markdown码字的过程。
以后我可能直接拿chatgpt回答的内容整理修改作为博客发布了。
剩下的依然有必要更新发布的博客内容，大概也就那种原创性的、和自己有关的内容，比如记录生活、记录想法、输出观点之类。
喝杯奶茶 </description>
    </item>
    
    <item>
      <title>PhotoPrism缺点大吐槽：哪哪都不行，建议弃用</title>
      <link>https://ruohai.wang/202412/photoprism-complains/</link>
      <pubDate>Thu, 05 Dec 2024 15:18:39 +0800</pubDate>
      
      <guid>https://ruohai.wang/202412/photoprism-complains/</guid>
      <description>前言 先声明：从去年的7~8月份我开始折腾自建相册，当时对比了immich最后选择了photoprism，至今也用了一年半的时间了，所以算是个老用户了，不是简单新手向的吐槽。
为什么用了一年半以后才开始写这个吐槽文，因为我自己用java写了一个小服务来处理照片归档，所以最后一个对pp的依赖也没有了，终于可以把pp从我的服务器上remove掉惹。
在放弃pp的这一刻，写篇文章记录一下我在使用pp的过程中碰到的几个超级大槽点。
超级大槽点 槽点一：照片统一重命名都按照UTC时区处理
这个是pp归档照片时最大的bug。
pp有个功能，就是按照统一规则生成一个唯一的文件名将照片进行重命名，所以最后的文件名都是yyyyMMdd_HHmmss_xxxxxxxx.jpg这种格式，其中最后8位x应该是类似md5一样根据文件生成的8位字符串。
这个功能很好用，也是强制启用的功能。按照这个规则重命名以后的照片/视频，根据文件名就能很方便的知道文件的创建时间，而且也统一了文件名，看上去很干净规整。
但是这个功能有个很大的bug！！！！
pp是按照utc时区来生成的文件名，也就是北京东八区的照片时间需要减去8个小时来生成文件名！！！
比如某时某刻我在东八区拍了一张jpg照片，拍摄时间是2024年12月5日15点36分44秒，那照片归档正确的文件名应该是20241205_153644_xxxxxxxx.jpg。但是pp会读取照片exif中的时区信息，换算成utc时区的时间生成文件名，也就是北京时间减去8个小时，最后就变成了20241205_073644_xxxxxxxx.jpg。
(╯‵□′)╯︵┻━┻
不过，比起原始照片文件各种乱七八糟无规则、无意义、自然递增的文件名格式，现在这个文件名只是时间少了8个小时，好像也不是太大的问题。
那就要配合上下面这个大杀器！
槽点二：照片归档也按照UTC时区处理
pp归档图片和视频文件时，是根据文件的创建时间，按照yyyy/mm的目录结构来归档文件的。
但是由于槽点一的存在，又导致了一种情况：
月初拍的照片有可能被归档到上个月！比如，2024年12月1号早上7点拍的照片，减去8小时是2024年11月30号晚上11点，就被归档到2024/11目录惹 年初拍的照片可能被归档到上一年！比如：2024年1月1日早上7点拍的照片，减去8小时候是2023年12月31日晚上11点，就被归档到2023/12目录惹 这种情况下，如果在pp中搜索2024年12月份的照片，或者搜2024年的照片，这种错误归档的照片就搜不到了！！！
(╯‵□′)╯︵┻━┻
我在使用photoprism的这一年半时间里，也想过是不是我什么地方没设置正确，比如是不是docker-compose.yml中没有加timezone参数，是不是服务器的时间设置错误。我在官方wiki和官方github issue里也找过，但实在是个人能力有限，没有找到什么有用的解决方法。我甚至在想，也许这是因为pp是一个面向全球用户的服务，开发团队为了解决那些经常往返不同时区的用户的照片归档问题，所以直接暴力的统一换算成utc时区。如果真的如此，那我要给pp开发团队送上1000个赞👍，这明显不是像我这种今生都没有离开过东八区的宅男能有的国际视野。
我非常喜欢pp这个按照文件时间统一命名的功能，虽然有换算成utc时区的大槽点，但另外几个相册（比如immich）都没有这个功能，所以最后我不得不继续坚持使用pp。
槽点三：图片算法识别功能很垃圾
pp作为一个完整的相册服务，也提供了图像算法识别功能，用来进行图像主体识别、人脸识别、自动标签、自动创建精彩时刻、图片质量打分等等智障功能。
但我实体使用下来的体验是：不好用，非常不好用。
不说和google、apple的图像识别算法对比，也不和国内各个手机厂商提供的手机智能相册比，只是和immich比，我都感觉差了很多。主体识别错误、检测不到人脸、自动标签错误，很难说达到可用级别。
对于pp的图像识别算法功能，我的点评是：能用但是不好用，徒增功耗、浪费算力，建议关闭。
槽点四：免费版pp的gps解析功能有限制
相信很多pp用户和我一样都是用的免费社区版（community）做自建相册，pp免费版也带了照片地图功能，根据照片exif中保存的gps信息显示照片的拍摄地并显示在地图上。
但是，但是，pp的骚操作又又又来惹！！！
免费版pp根据gps坐标数据解析地理位置的api有请求数量限制！！！有rate limit！！！
也就是如果导入比较多的照片，很容易就达到这个reverse geocodeing接口的请求数量限制，这个api会超时无响应报timeout错误让你以为是自己网络出了问题。因为immich就有很多请求是访问google，如果不挂科学上网使用immich，查看日志的时候会看到大量的timeout请求。
如果不小心触发了这个rate limit，很抱歉你的pp解析照片地理位置的功能就gg了。
如果你在导入照片的时候，导到中途免费请求次数用完了，会发生什么：
剩下的照片依然能导入，只是剩下的照片都没有地理信息了 解析照片gps的请求依然会发起，但每次都是超时无响应（timeout），这个超时要等好几秒，导致整个导入过程变成非常慢 在官方wiki我没有查到明确的免费请求次数，也没有查到如果免费请求次数耗尽以后是否会隔天重置。
不过作为免费白嫖党，官方对此功能做出rate limit也算可以理解，因为官方提供这个服务需要开销，只是让付费用户分摊了。
如果你是pp重度用户，建议花钱订阅支持pp，就可以无限制使用照片地理信息解析的接口惹。
如果你和我一样是pp白嫖党，建议关闭pp的【地点】功能。
槽点五：普通图片的时间信息提取规则不完善
首先定义下这里说的普通图片。这里把用手机、相机拍摄而成的图片称之为【拍摄行为】产生的照片，把存的网图、微信图、截图、微博图称之为【非拍摄行为】产生的普通图片。
pp在将文件进行归档时，需要提取文件的时间信息。如果是照片文件，这类文件的exif中都有完整的Date/Time Original、 Date/Time Digitized信息，只需要读取这些tag中保存的时间字符串解析成时间，然后用这个时间给文件重新命名就行了（别忘了会减去8个小时）。
如果是普通图片，这种文件的exif中没有Date/Time Original、 Date/Time Digitized这些tag，那要如何提取这个文件的时间呢？
经过我的摸索，pp提取文件时间信息的规则优先级如下：
Date/Time Original、 Date/Time Digitized：这俩tag可以理解位照片的拍摄时间，pp读到这个时间后会按照utc时区处理 从文件名中提取时间：图片文件的exif没有以上两个tag，但文件名中包含了时间信息，比如Snipaste_2024-12-05_20-50-36.jpg，只需要拿到2024-12-05_20-50-36这段字符进行解析即可。这个规则下，pp读到什么时间就是什么时间，不会处理时区。 如果以上两个规则都无法提取到文件的时间，则以系统当前时间为准，pp读到这个时间后也会按照utc时区处理 这些规则不仅仅是pp在用，其它相册服务应该也大差不差。
从以上规则可以看出，普通图片文件很容易因为无法满足规则1、规则2，最后在归档时，直接以系统当前时间给文件重命名。从某种程度上说，这倒也无可厚非，毕竟没有其它方法获取这种文件的创建时间了，只能用这种方式作为保底。
但是，是的，又要接一个但是，为什么这也会成为pp的一个大槽点？
因为pp的规则2（从文件名中提取时间）甚至都不支持它自己的归档文件名格式，也就是yyyyMMdd_HHmmss_xxxxxxxx，pp碰到这么标准的文件名竟然无法提取时间，最后会按照规则3给文件重命名！！！
这个bug会导致的问题就是：用pp归档过一次的文件，如果重新导入pp，那这些普通图片文件都会按照系统当前时间进行重命名和归档！也就是这些普通文件不管第一次导入时被归档到哪天，在二次导入时，都会被归档到今天。
你可能会觉得奇怪，为什么会有傻x把已经归档过的照片反复导入pp归档。</description>
    </item>
    
  </channel>
</rss>
