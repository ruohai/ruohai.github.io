<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>202405s on 喵ฅ^•ﻌ•^ฅ</title>
    <link>https://ruohai.wang/202405/</link>
    <description>Recent content in 202405s on 喵ฅ^•ﻌ•^ฅ</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh-cn</language>
    <lastBuildDate>Thu, 30 May 2024 16:22:10 +0800</lastBuildDate><atom:link href="https://ruohai.wang/202405/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>在Debian下的简单网络配置与重启</title>
      <link>https://ruohai.wang/202405/network-interface-change-on-debian/</link>
      <pubDate>Thu, 30 May 2024 16:22:10 +0800</pubDate>
      
      <guid>https://ruohai.wang/202405/network-interface-change-on-debian/</guid>
      <description>debian系统配置静态ip之前已经写过一篇笔记，但时隔久远，重新记录一下。
配置文件路径/etc/network/interfaces
固定ip/静态ip
假定网卡名称是eth0，设置静态ip的配置如下，其中的具体参数根据自己的实际情况调整。
# 开机自动启用eth0 auto eth0 # 使用静态ip iface eth0 inet static # ip地址 address 192.168.1.4 # 子网掩码 netmask 255.255.255.0 # 网关地址 gateway 192.168.1.1 # dns服务器 dns-nameservers 192.168.1.1 其中的auto指在系统启动时获取网络信息，如果你的使用环境需要经常热插拔网线，可以改成allow-hotplug，意指网线热插拔以后可以重新获取网络。
切换网卡
如果机器上有两个网卡，比如一个有线一个无线，依然是编辑/etc/network/interfaces，把原来的primary network interface注释，改成自己需要的网卡。
重启网络
debian下重启网络
systemctl restart networking.service 参考文章 Debian 中 allow-hotplug 与 auto 的区别 </description>
    </item>
    
    <item>
      <title>记录一次照片文件的去重操作</title>
      <link>https://ruohai.wang/202405/deduplicate-media-files/</link>
      <pubDate>Fri, 24 May 2024 19:39:46 +0800</pubDate>
      
      <guid>https://ruohai.wang/202405/deduplicate-media-files/</guid>
      <description>最近因为频繁的刷机 &amp;amp; 部署photoprism，导致有一个盘上已经按照photoprism的入库规则统一重命名 &amp;amp; 归档的400张照片忘记全部备份到群晖，然后又二次误操作把这几百张照片导入了新部署的photoprism。
这时候就出现了一个重复文件的问题：
这400张照片，一部分已经备份到群晖，一部分没有。备份用的是rsync整个目录增量备份。 新部署的photoprism中，已经有100多张新照片，这次又二次导入了400张老照片，是新旧混杂的状态。 导入photoprism的照片，都会按照yyyyMMdd-hhmmss-xxxxxx这种年月日-时分秒-随机六位字符的格式作为唯一编号进行重命名，也就意味着这几百张二次导入的照片，文件名应该都发生了变化，变成了新文件，再用rsync增量备份的时候应该都会备当作新文件重复备份到群晖。 作为有轻微电子洁癖的我肯定受不了这种nas里出现几百张重复照片的事情，所以立刻想着怎么去重。
当时想到的有两个方案：
先全部备份到群晖，然后用群晖的重复文件检验功能筛选出重复文件的清单，最后手动清理群晖中的重复文件 使用第三方去重软件，比如alldup 这俩方法可行性都挺高的，虽然都略微繁琐，但最后肯定能实现去重的目的。
不过这俩方法我都没有用。因为前者需要把文件导入到群晖后，在群晖里操作。群晖里有我这十多年来的接近10万份个人文件，我担心在群晖里把文件弄乱，那就彻底gg。后者alldup支持smb网络文件夹，但是会把需要校验的文件都缓存到本地来计算hash。
因为我手上万幸还保留着那400张老照片，简单记录一下我的处理思路：
去重的核心是只修改文件名不会让文件的hash发生变化 先把400张老照片全量备份到群晖，解决这些老照片部分已备份 + 部分未备份的问题 接下去只需要比对photoprism图库中的全部照片 vs 400张老照片 在部署photoprism的armbian盒子上，用sha256sum获取到所有新文件和旧文件的hash值 + 文件名的清单 将上一步得到的清单粘贴到excel，用vlookup筛选出重复文件，以及这些重复文件的新文件名 写一个超级简单的bash脚本，直接将新重复的新文件从photoprism中删除 在photoprism中对资料库进行清理，将已经删除的文件清除索引 最后方便 &amp;amp; 快速的完成了文件去重而且0误伤。🎉
这个方案的好处是
不在群晖里操作，避免搞乱群晖的文件 在linux操作的命令也很简单，只需要进入照片目录，执行sha256sum * &amp;gt; hush.log就可以获取到全部的hash filename格式的文本清单。 比对和筛选重复文件时在excel中用vlookup来完成，非常简单易懂直观 获取到最终要删除的文件名清单以后，只需要写一个很简单的bash脚本就可以批量删除文件 bash脚本如下：
最后，本次操作还发现一个新知识点：photoprism在归档照片的时候，如果照片的exif完整，包含拍摄时间这个参数，那生成的新文件名是固定的。
之前我一直以为photoprism的文件名规则中最后六位字符是随机字符，实测不是的，是固定值。</description>
    </item>
    
    <item>
      <title>在Windows上编译Memos的前端项目</title>
      <link>https://ruohai.wang/202405/memos-frontend-compile-on-windows/</link>
      <pubDate>Thu, 23 May 2024 19:03:48 +0800</pubDate>
      
      <guid>https://ruohai.wang/202405/memos-frontend-compile-on-windows/</guid>
      <description>前言 memos很好用，是我高频使用的一个服务，自从我的twitter炸号以后我已经把memos当作自建twitter（或者自建微博）在使用。
memos官方一直只维护docker部署的方式，确实挺方便的，一键安装不用操心什么环境、依赖、硬件架构的问题。
但我还是渐渐的想脱离docker环境使用memos。前几天写了一篇文章写怎么编译memos前端，那篇是根据项目的github仓库的issues中很多人的回答总结出来的。但写完文章就发现其实正确的编译方法已经完整的写在源码的dockerfile文件里了。
所以这次再次自己动手，开始编译前端项目。
你可能要问为什么后端项目也自己编译，🤔，因为后端二进制包受宿主系统的硬件架构限制，amd64上编译出来的包没法在arm32平台上跑，甚至我在arm32平台上编译的包（libc）在musl的openwrt上都跑不起来。所以后端项目我直接用了github上现成编译好的，就不自己折腾了。
又因为我是windows用户，所以我用来编译的环境就是windows惹，其它系统其实也没区别，自行理解就行。
编译 先准备前端项目的编译环境，参考dockerfile中要求的版本号，实测更高版本也可以。
node，版本18 buf，版本1.26.1 先从memos的官方github项目主页下载源码、解压这些就不说了。因为从v0.15升级到v0.16涉及到数据库的表结构变更，我暂时不想步子迈这么大，所以这次以v0.15.2为例。
buf官方提供了二进制包，可以直接下载使用。指路：【bufbuild/buf】
下载后最好放到memos项目源码的proto目录（windows下应该叫做文件夹，但这里还是用linux的习惯叫目录）。
然后打开windows terminal（没有terminal就用cmd，下同），进入这个目录，执行buf-Windows-x86_64.exe generate。因为没有设置环境变量，所以这里buf命令需要用完整的文件名。
运行完以后没有报错的话就ok惹。
然后用管理员权限启动windows terminal（因为非管理员账户执行pnpm可能会提示权限不足）。
进入到memos项目源码的web目录，执行以下命令：
corepack enable &amp;amp;&amp;amp; pnpm i --frozen-lockfile 等命令跑完以后，提示内容大致如下：
然后继续执行命令pnpm build
跑完以后提示如下：
到这里整个前端项目的编译工作就结束惹，接下去只需要把web目录下的dist目录整个复制出来放到项目的server目录下即可。
项目结构示意：
--memos --server | --dist 不过这个目录结构仅限于v0.15，后续版本我看到是调整过目录结构，具体请根据dockerfile里的部署方式来调整。
好了，恭喜你编译成功，接下去就可以脱离docker环境直接跑memos惹。
🎉</description>
    </item>
    
    <item>
      <title>在OpenWrt上安装ttyd</title>
      <link>https://ruohai.wang/202405/ttyd-install-one-openwrt/</link>
      <pubDate>Tue, 21 May 2024 20:47:37 +0800</pubDate>
      
      <guid>https://ruohai.wang/202405/ttyd-install-one-openwrt/</guid>
      <description>前言 简单交代一下我想要跑ttyd的硬件和系统。
我的硬件是迅雷赚钱宝一代，硬件型号ws1408，228MB的内存，amlogic s805芯片。
我给这硬件刷的系统是openwrt21，内核3.10。
其实openwrt的软件仓库就带了luci-ttyd，但我觉得用起来不方便，要登录openwrt——服务——ttyd，然后二次登录。除此之外，luci-ttyd的窗口大小也受限制，没法做到浏览器全屏。
所以最后还是用二进制包的方式在openwrt上安装一遍ttyd。
安装 第一步：下载
ttyd的github项目主页指路：【tsl0922/ttyd】，在release页面找到对应版本的二进制包。ws1408是arm32/armhf/armv7l，三种叫法都对。我这里选择ttyd.armhf。
wget -O ttyd https://github.com/tsl0922/ttyd/releases/download/1.7.7/ttyd.armhf 注意看下下载的文件是不是有可执行权限，没有的话chmod +x ttyd赋权。
第二步：sysv脚本
在/etc/init.d目录下新建文件ttyd，然后粘贴以下代码，端口号和文件路径请自行调整：
#!/bin/sh /etc/rc.common START=99 STOP=10 SERVICE_WRITE_PID=1 SERVICE_USE_PID=1 SERVICE_DAEMONIZE=1 start() { service_start /mnt/data/ttyd/ttyd -p 12345 -W login } stop() { kill $(pidof ttyd) } 保存后退出，然后给文件添加可执行权限，chmod +x ttyd。
这里有两个个注意点，第一是ttyd从某个版本以后默认是只读权限了，启动命令需要添加-W参数才会有写入权限。第二是我这个脚本只适配了start和stop命令，其它的restart没做适配，有需求的可以自己参考sysvinit的语法补足。
第三步：ttyd启动
看了这么多篇在openwrt上装软件的博客，启动和添加启动项大家应该都很熟练了。
# 启动 service ttyd start # 添加启动项 service ttyd enable 好了，到这里在openwrt上运行ttyd二进制包的操作就完成惹。
🎉</description>
    </item>
    
    <item>
      <title>非Docker方式在Openwrt上运行Memos</title>
      <link>https://ruohai.wang/202405/memos-run-on-openwrt-without-docker/</link>
      <pubDate>Mon, 20 May 2024 00:32:48 +0800</pubDate>
      
      <guid>https://ruohai.wang/202405/memos-run-on-openwrt-without-docker/</guid>
      <description>前言 长话短说了。
Memos的开发者只提供了docker镜像这一种部署方式，而且从v0.15.0以后已经停止维护针对arm32/armhf/armv7l的版本。
我的系统是3.10内核的openwrt 21，因为内核太老所以不支持安装docker。
我的硬件是迅雷赚钱宝一代，硬件型号ws1408，芯片amlogic s805，内存228MB。
我用的memos后端是v0.15.2，是从github下载的，指路：【memospot/memos-builds】。
你可能会问为什么不用更高的版本，😂，有苦衷的。其一是因为前端部分需要自己编译，我只成功编译出了v0.15.0版本，更新的版本我本地编译都会报错，暂时没有精力去debug。其二是因为之前受arm32平台的限制，我一直用的是v0.15.0的docker镜像，而从v0.16开始的更新就涉及到数据库表结构的变更，没法平滑的升级，所以本次还是停留在v0.15这个大版本。
至于后端v0.15.2 + 前端v0.15.0这种奇怪的版本组合，😂，我用了一个周末，还没有发现什么bug，可以正常使用。
我自己编译的v0.15.0的前端项目的下载放在文章最后。
这种方式也适用于在其它linux版本上直接用编译好的二进制包运行memos，自行调整配置文件即可。
配置 先把v0.15.2的后端 + v0.15.0的前端上传到服务器，然后按照项目结构进行组织。后端文件memos不要忘记添加可执行权限，chmod +x memos。
--memos --server | --dist 我的项目结构如下图，其中data用来存放memos的数据。
接下去就是配置启动脚本以及一些bug处理。
第一步：sysv脚本
在/etc/init.d目录下新建文件memos，记得添加可执行权限chmod +x memos，然后粘贴以下代码。其中的文件路径、端口号、数据存放目录请自行修改。
#!/bin/sh /etc/rc.common START=99 STOP=10 SERVICE_WRITE_PID=1 SERVICE_USE_PID=1 SERVICE_DAEMONIZE=1 start() { service_start /mnt/data/memos/memos --mode=prod --port=5203 --data=/mnt/data/memos/data } stop() { kill $(pidof memos) } 保存后退出，然后启动服务并设置开机启动。
# 启动服务 service memos start # 添加启动项 service memos enable 注意这个脚本只设置了start和stop两个命令，其它的restart之类都没有适配，有需求的话请自行添加代码。
第二步：设置缩略图目录
memos应该是硬编码了到/var/opt/memos/assets这个附件目录下索引图片来生成缩略图，但我们用二进制包运行memos的话，数据存放路径都会自定义设置，其次是openwrt系统下，/var目录是个临时目录，一重启就会清空数据，所以肯定要修正这个bug。
比如我的memos数据都存放在/mnt/data/memos/data目录下。
解决的方法是建立一个软连接，把附件目录指向我们自定义的附件目录。
# 新建目录 mkdir -p /var/opt/memos/ # 把硬编码的目录通过软链接指向我们自己的数据目录 ln -s /mnt/data/memos/data/assets/ /var/opt/memos/assets 但机器可能偶尔会重启，一重启整个/var目录会被清空，不可能每次重启都手动创建一遍目录 + 软连接，所以需要把这个操作添加到启动项。</description>
    </item>
    
    <item>
      <title>在刷了Armbian的玩客云（WS1608）上编译Memos教程</title>
      <link>https://ruohai.wang/202405/memos-compile-one-onecloud/</link>
      <pubDate>Fri, 17 May 2024 12:52:28 +0800</pubDate>
      
      <guid>https://ruohai.wang/202405/memos-compile-one-onecloud/</guid>
      <description>前言 memos是一个很不错的开源笔记服务，我在刷了armbian的迅雷赚钱宝二代（下称小飞碟）上用docker方式部署了一个自己的memos，已经高强度使用至今。
但玩过迅雷赚钱宝系列的垃圾佬肯定知道这系列机器从一代到三代，用的芯片都是amlogic s805，架构是arm32/armv7l/armhf，而memos官方从v0.15.0开始就不再发布针对该硬件架构的docker镜像。因为如此，所以我使用的memos一直停留在0.15.0，坏处当然是用不上最新版、体验不到新特性，不过也有好处，至少稳定、不折腾了用了半年。
在docker hub上也能搜到第三方发布的针对各个硬件架构的memos的镜像，比如这个：【lincolnthalles/memos】，几乎覆盖了全部可能的硬件。
但我还想更geek一点，我想不再囿于docker，而是直接用源码编译出memos的二进制包，然后把编译出来的memos丢到刷了openwrt的机器上跑。
先说一下结果：
成功的编译出了arm32/armv7l/armhf版本的memos，可以在刷了armbian的玩客云/小飞碟上正常跑 编译出来的memos在openwrt上跑不起来，目测应该是openwrt是musl而编译出来memos用的libc 尝试直接在openwrt上编译，没成功 虽然最终的目的没有达成，但至少也成功了一半。所以写篇博客，记录一下过程，也许能帮到你。
环境准备 编译memos项目，分成前端和后端两个部分。
编译后端，需要golang，我用的debian仓库里的golang，直接apt install golang即可，版本1.19。
编译前端需要nodejs，最好再装个yarn。
因为玩客云的内存太小，我尝试在玩客云上直接编译前端项目时会因为oom而中断。考虑到前端项目的代码不区分硬件平台，所以我是在windows电脑上编译的前端项目然后再copy到玩客云上。
nodejs设置镜像源、go设定GOPATH、解决网络问题这些属于基操了，不再赘述。
编译环境准备好了以后，接下去就开始吧！
开始编译 从github下载源码，解压，进入项目根目录这些操作略过。
前端
进入web目录用yarn编译，执行以下命令
# 进目录 cd web # 安装依赖 yarn # 打包 yarn build 编译完成后，把web目录下生成的dist/目录整个复制到/server/dist/下，也就是
mv web/dist server/dist 如果你跟我一样在其它机器上编译的前端项目，同样只需要把web目录下的dist/复制到最终机器上的server目录下就可以了。
到这里，前端项目编译完成。
后端
在项目根目录执行命令
go build -o memos ./main.go 命令跑完以后在项目根目录下会出现一个memos的文件，就是编译好的后端了。
关于后端编译有一个坑需要注意，就是，比如我在/mnt/data/memos.v0.15.0目录下编译出了一个memos后端，那这个memos后端只会去/mnt/data/memos.v0.15.0/server/dist目录下找前端，aka后端文件中的前端项目路径在编译的时候就写死了。如果把编译好的memos后端放到其它目录下，就会找不到前端项目。
运行
前端和后端都编译完成后，最终我们需要的项目结构如下：
----memos_project |--memos |--server |--dist |--assets |--index.html |--logo.webp |--manifest.json |--sw.js |--... 最后在项目根目录下执行命令即可，记得根据自己喜好调整端口号和数据保存路径。
./memos --mode=prod --port=5230 --data=/path/to/save/data 看到这个界面就算是成功惹，打开浏览器，访问http://host-ip:5230就可以使用自己编译的memos。
systemd配置文件</description>
    </item>
    
    <item>
      <title>在刷了OpenWrt的迅雷赚钱宝一代（WS408）上安装Navidrome教程</title>
      <link>https://ruohai.wang/202405/navidrome-install-on-ws1408/</link>
      <pubDate>Wed, 15 May 2024 18:36:51 +0800</pubDate>
      
      <guid>https://ruohai.wang/202405/navidrome-install-on-ws1408/</guid>
      <description>前言 迅雷赚钱宝一代（下称小方块）这机器折腾到现在，相信你也摸出规律了，但凡是支持armbian32/armhf/armv7l的软件，只要有已经编译好的二进制包，在openwrt上都能跑，无非就是需要自己动手写一个sysvinit版本的启动脚本。
这么看来，小方块上还能继续安装navidrome、hugo、alist、ttyd等等我之前装在armbian小盒子上的服务。既然都有alist了，那挂个小雅合集也不是难事。
说远了，这篇文章就简单说一下怎么装navidrome
安装 第一步：下载
首先就是去navidrome项目的github仓库找安装包，项目地址【navidrome/navidrome】。
在release页面找到armv7版本的包，复制链接
然后用wget命令下载到本地并解压
# 下载 wget -O navidrome.tar.gz https://github.com/navidrome/navidrome/releases/download/v0.52.5/navidrome_0.52.5_linux_armv7.tar.gz # 解压 tar -zxvf navidrome.tar.gz 解压以后看到navirome二进制包已经有可执行权限了，如果没有的话，执行一下chmod +x navidrome即可。
第二步：编辑配置文件
在二进制包的目录下，新建配置文件
# 新建 touch navidrome.toml # 编辑(没有nano就用vim) nano navidrome.toml 在配置文件中，有以下几个参数需要指定：
MusicFolder：歌曲文件所在目录 DataFolder：软件运行数据的存放目录，默认是./data，也就是当前目录下新建一个/data目录 Port：端口号，默认是4533 除了以上三个我觉得比较重要，其它更多参数可以看官方的手册，指路：【Navidrome/Available Options】
比如我的配置如下：
编辑完成后保存即可。
第三步：编辑启动脚本
现在到最后一步了，需要编辑一份适合sysvinit的启动脚本。
# 进目录 cd /etc/init.d # 新建 touch navidrome # 编辑 nano navidrome 我提供一个最简单可用的版本(里面的文件路径记得自行调整)：
#!/bin/sh /etc/rc.common START=96 STOP=10 SERVICE_WRITE_PID=1 SERVICE_USE_PID=1 SERVICE_DAEMONIZE=1 start() { service_start /mnt/sdcard/navidrome/navidrome --configfile &amp;#34;/mnt/sdcard/navidrome/navidrome.toml&amp;#34; } stop() { kill $(pidof navidrome) } 粘贴以后保存退出。</description>
    </item>
    
    <item>
      <title>在刷了OpenWrt的迅雷赚钱宝一代（WS1408）上开启Swap交换分区</title>
      <link>https://ruohai.wang/202405/swapon-on-ws1408/</link>
      <pubDate>Wed, 15 May 2024 17:44:08 +0800</pubDate>
      
      <guid>https://ruohai.wang/202405/swapon-on-ws1408/</guid>
      <description>前言 不知直觉已经在我的迅雷赚钱宝一代ws1408（下称小方块）上部署了不少服务，比只有70MB可用的存储空间更金贵的，是只有228MB可用的运行内存。
这点内存，稍微跑几个服务就容易oom，比如qbittorrent-nox，很容易闪退。虽然之后我在qbit的设置中调小了内存占用的数值，但依然会出现10GB的大文件下载完成后校验时闪退。
我刷的openwrt21固件默认不启用swap分区。在经历了好几次oom以后，痛定思痛，我准备开启swap分区来缓解小方块内存太小的问题。
配置 小方块有两个扩展接口，一个tf卡槽，一个usb2.0接口。
我在机器上插了一张tf卡挂载到/mnt/sdcard作为存储空间用，留下usb2.0来外接硬盘作为数据盘。所以这次的思路是，在sd卡上创建一个200MB的swap文件作为系统的swap分区使用。关于swap分区的大小应该设置成多少，很多古董文章里都说要设置成内存的2倍大小，不用机械的按照这个奇怪的规则去设定，设定成和内存同样大小、1/2大小、5倍大小都可以，根据自己的实际情况来定就可以。
tf卡的i/o性能肯定没法和内存相提并论，实测开启swap以后，系统的响应速度都会被拖慢，但好处也很明显，可以部署大量的服务而不用担心oom惹。
第一步：创建swap文件
先新建一个200MB大小的文件。
可以用dd命令
dd if=/dev/zero of=/mnt/sdcard/swap bs=1M count=200 也可以用fallocate命令
fallocate -l 200M /mnt/sdcard/swap 第二步：格式化
将创建的指定大小的swap文件格式化为swap文件系统
mkswap /mnt/sdcard/swap 第三步：启动swap设备
执行命令
swapon /mnt/sdcard/swap 到这一步以后，可以用free -m或者htop工具来查看swap是否已经启用。
htop
free -m
第四步：设定开机自动挂载swap
网上很多文章到这一步都会让设置/etc/fstab然后把swap挂载信息写上去，这个方法需要block-mount工具的支持，小方块的openwrt默认并没有安装这个工具。
所以这里用的添加启动脚本的方法来解决。在自动挂载sdcard的命令后面，加上一条启动swap的命令即可。
swapon /mnt/sdcard/swap 最后点击保存。
到这里，在openwrt上开启swap的操作就全部完成惹。
🎉</description>
    </item>
    
    <item>
      <title>在刷了OpenWrt的迅雷赚钱宝一代（WS1408）上安装Tailscale教程</title>
      <link>https://ruohai.wang/202405/tailscale-install-on-ws1408/</link>
      <pubDate>Tue, 14 May 2024 18:42:33 +0800</pubDate>
      
      <guid>https://ruohai.wang/202405/tailscale-install-on-ws1408/</guid>
      <description>前言 先说明一下我的迅雷赚钱宝一代ws1408（下文称做小方块）刷的系统是openwrt 21.02.7（文章末尾有下载链接），内核3.10.33。
之前没有想到这个小方块的可玩性还挺强，因为内核太老、内存太小导致没有什么可用的固件，只能基于现有的openwrt固件来屎上雕花，让它继续发光发热了。
tailscale官方只提供了一键安装的脚本，那我们只能找第三方编译好的安装包了，项目地址：【Azathothas/Static-Binaries】。
有了已经编译好的安装包，那我们就开始吧！
安装 【Azathothas/Static-Binaries】项目的release页面提供的二进制包，不仔细看还以为同样的包提供了两份，仔细看一个是tailscale，另一个是tailscaled。
根据我浅薄的linux使用经验，名称中带d的那个肯定就是守护进程的版本惹。
项目的手册中提供了安装教程，地址【Install TailScale】，英文阅读无障碍的话直接看项目手册就行。
根据我实际安装的经验，tailscale不带d的这个安装包，是用来进行初始化配置的（比如设置子网路由、关联tailscale账号），tailscaled带d的安装包，是实际运行的服务程序。所以，想要跑tailscale，需要两个安装包都下载到本地。
不过项目的release页面还提供了merged版本，看名字我觉得是二合一版本，但实际测试发现还是俩包分开的比较容易上手，所以这篇文章不聊这个merged版本。
第一步：下载
小方块用的芯片是我们的老朋友amlogic s805，硬件架构是arm32/armv7l/armhf，固件openwrt用的init系统是sysv，根据这些信息找到正确的安装包：
注意有两个安装包，一个是初始化配置用的、不带d的tailscale，一个是带d的tailscaled。
# 下载tailscaled wget -O tailscaled https://github.com/Azathothas/Static-Binaries/releases/download/tailscale_v1.66.1/tailscaled_arm_abi_Linux # 下载tailscale wget -O tailscale https://github.com/Azathothas/Static-Binaries/releases/download/tailscale_v1.66.1/tailscale_arm_abi_Linux # 给俩文件添加可执行权限 chmod +x tailscale tailscaled 到这里，下载的步骤就完成了。
第二步：将tailscaled添加为sysv服务
网上搜了一圈没找到tailscale的sysv配置文件，所以根据以往经验，再参考systemd版本的配置文件，可用的sysv配置文件如下。我的tailscale文件保存在/mnt/sdcard目录下，请根据自己的实际情况调整这个路径。
# 进入目录 cd /etc/init.d/ # 创建配置文件 touch tailscaled # 编辑配置文件(没有nano可以用vim) nano tailscaled 然后把这段代码粘贴进去，保存退出。
#!/bin/sh /etc/rc.common START=96 STOP=10 SERVICE_WRITE_PID=1 SERVICE_USE_PID=1 SERVICE_DAEMONIZE=1 start() { service_start /mnt/sdcard/tailscale/tailscaled --state=/mnt/sdcard/tailscale/tailscaled.state --socket=/mnt/sdcard/tailscale/tailscaled.sock --port=123456 } stop() { service_stop /mnt/sdcard/tailscale/tailscaled --cleanup } 最后给文件添加可执行权限并启动</description>
    </item>
    
  </channel>
</rss>
