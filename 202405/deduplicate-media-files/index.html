<!doctype html>
<html lang="zh-cn">
  <head>
    <title>记录一次照片文件的去重操作 // 喵ฅ^•ﻌ•^ฅ</title>
    <link rel="shortcut icon" href="/favicon.ico" />
    <meta charset="utf-8" />
    <meta name="generator" content="Hugo 0.111.3">
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="Ruohai Wang" />
    <meta name="description" content="" />
    <link rel="stylesheet" href="/css/main.min.da30c98f9942ec671d45447781f2ff089c06a4c2f4fc85c728b8f8755627a970.css" />
    

    
    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="记录一次照片文件的去重操作"/>
<meta name="twitter:description" content="最近因为频繁的刷机 &amp; 部署photoprism，导致有一个盘上已经按照photoprism的入库规则统一重命名 &amp; 归档的400张照片忘记全部备份到群晖，然后又二次误操作把这几百张照片导入了新部署的photoprism。
这时候就出现了一个重复文件的问题：
这400张照片，一部分已经备份到群晖，一部分没有。备份用的是rsync整个目录增量备份。 新部署的photoprism中，已经有100多张新照片，这次又二次导入了400张老照片，是新旧混杂的状态。 导入photoprism的照片，都会按照yyyyMMdd-hhmmss-xxxxxx这种年月日-时分秒-随机六位字符的格式作为唯一编号进行重命名，也就意味着这几百张二次导入的照片，文件名应该都发生了变化，变成了新文件，再用rsync增量备份的时候应该都会备当作新文件重复备份到群晖。 作为有轻微电子洁癖的我肯定受不了这种nas里出现几百张重复照片的事情，所以立刻想着怎么去重。
当时想到的有两个方案：
先全部备份到群晖，然后用群晖的重复文件检验功能筛选出重复文件的清单，最后手动清理群晖中的重复文件 使用第三方去重软件，比如alldup 这俩方法可行性都挺高的，虽然都略微繁琐，但最后肯定能实现去重的目的。
不过这俩方法我都没有用。因为前者需要把文件导入到群晖后，在群晖里操作。群晖里有我这十多年来的接近10万份个人文件，我担心在群晖里把文件弄乱，那就彻底gg。后者alldup支持smb网络文件夹，但是会把需要校验的文件都缓存到本地来计算hash。
因为我手上万幸还保留着那400张老照片，简单记录一下我的处理思路：
去重的核心是只修改文件名不会让文件的hash发生变化 先把400张老照片全量备份到群晖，解决这些老照片部分已备份 &#43; 部分未备份的问题 接下去只需要比对photoprism图库中的全部照片 vs 400张老照片 在部署photoprism的armbian盒子上，用sha256sum获取到所有新文件和旧文件的hash值 &#43; 文件名的清单 将上一步得到的清单粘贴到excel，用vlookup筛选出重复文件，以及这些重复文件的新文件名 写一个超级简单的bash脚本，直接将新重复的新文件从photoprism中删除 在photoprism中对资料库进行清理，将已经删除的文件清除索引 最后方便 &amp; 快速的完成了文件去重而且0误伤。🎉
这个方案的好处是
不在群晖里操作，避免搞乱群晖的文件 在linux操作的命令也很简单，只需要进入照片目录，执行sha256sum * &gt; hush.log就可以获取到全部的hash filename格式的文本清单。 比对和筛选重复文件时在excel中用vlookup来完成，非常简单易懂直观 获取到最终要删除的文件名清单以后，只需要写一个很简单的bash脚本就可以批量删除文件 bash脚本如下：
最后，本次操作还发现一个新知识点：photoprism在归档照片的时候，如果照片的exif完整，包含拍摄时间这个参数，那生成的新文件名是固定的。
之前我一直以为photoprism的文件名规则中最后六位字符是随机字符，实测不是的，是固定值。"/>

    <meta property="og:title" content="记录一次照片文件的去重操作" />
<meta property="og:description" content="最近因为频繁的刷机 &amp; 部署photoprism，导致有一个盘上已经按照photoprism的入库规则统一重命名 &amp; 归档的400张照片忘记全部备份到群晖，然后又二次误操作把这几百张照片导入了新部署的photoprism。
这时候就出现了一个重复文件的问题：
这400张照片，一部分已经备份到群晖，一部分没有。备份用的是rsync整个目录增量备份。 新部署的photoprism中，已经有100多张新照片，这次又二次导入了400张老照片，是新旧混杂的状态。 导入photoprism的照片，都会按照yyyyMMdd-hhmmss-xxxxxx这种年月日-时分秒-随机六位字符的格式作为唯一编号进行重命名，也就意味着这几百张二次导入的照片，文件名应该都发生了变化，变成了新文件，再用rsync增量备份的时候应该都会备当作新文件重复备份到群晖。 作为有轻微电子洁癖的我肯定受不了这种nas里出现几百张重复照片的事情，所以立刻想着怎么去重。
当时想到的有两个方案：
先全部备份到群晖，然后用群晖的重复文件检验功能筛选出重复文件的清单，最后手动清理群晖中的重复文件 使用第三方去重软件，比如alldup 这俩方法可行性都挺高的，虽然都略微繁琐，但最后肯定能实现去重的目的。
不过这俩方法我都没有用。因为前者需要把文件导入到群晖后，在群晖里操作。群晖里有我这十多年来的接近10万份个人文件，我担心在群晖里把文件弄乱，那就彻底gg。后者alldup支持smb网络文件夹，但是会把需要校验的文件都缓存到本地来计算hash。
因为我手上万幸还保留着那400张老照片，简单记录一下我的处理思路：
去重的核心是只修改文件名不会让文件的hash发生变化 先把400张老照片全量备份到群晖，解决这些老照片部分已备份 &#43; 部分未备份的问题 接下去只需要比对photoprism图库中的全部照片 vs 400张老照片 在部署photoprism的armbian盒子上，用sha256sum获取到所有新文件和旧文件的hash值 &#43; 文件名的清单 将上一步得到的清单粘贴到excel，用vlookup筛选出重复文件，以及这些重复文件的新文件名 写一个超级简单的bash脚本，直接将新重复的新文件从photoprism中删除 在photoprism中对资料库进行清理，将已经删除的文件清除索引 最后方便 &amp; 快速的完成了文件去重而且0误伤。🎉
这个方案的好处是
不在群晖里操作，避免搞乱群晖的文件 在linux操作的命令也很简单，只需要进入照片目录，执行sha256sum * &gt; hush.log就可以获取到全部的hash filename格式的文本清单。 比对和筛选重复文件时在excel中用vlookup来完成，非常简单易懂直观 获取到最终要删除的文件名清单以后，只需要写一个很简单的bash脚本就可以批量删除文件 bash脚本如下：
最后，本次操作还发现一个新知识点：photoprism在归档照片的时候，如果照片的exif完整，包含拍摄时间这个参数，那生成的新文件名是固定的。
之前我一直以为photoprism的文件名规则中最后六位字符是随机字符，实测不是的，是固定值。" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://ruohai.wang/202405/deduplicate-media-files/" /><meta property="article:section" content="202405" />
<meta property="article:published_time" content="2024-05-24T19:39:46+08:00" />
<meta property="article:modified_time" content="2024-05-24T19:39:46+08:00" />


  </head>
  <body>
    <header class="app-header">
      <a href="https://ruohai.wang/"><img class="app-header-avatar" src="/avatar.jpg" alt="Ruohai Wang" /></a>
      <span class="app-header-title">喵ฅ^•ﻌ•^ฅ</span>
      <nav class="app-header-menu">
          <a class="app-header-menu-item" href="/">主页</a>
             - 
          
          <a class="app-header-menu-item" href="/tags/">标签</a>
             - 
          
          <a class="app-header-menu-item" href="/about/">关于</a>
      </nav>
      <p>这种失落会持久吗~</p>
      <div class="app-header-social">
        
          <a href="https://t.me/ruohai" target="_blank" rel="noreferrer noopener me">
            <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-twitter">
  <title>Twitter</title>
  <path d="M23 3a10.9 10.9 0 0 1-3.14 1.53 4.48 4.48 0 0 0-7.86 3v1A10.66 10.66 0 0 1 3 4s-4 9 5 13a11.64 11.64 0 0 1-7 2c9 5 20 0 20-11.5a4.5 4.5 0 0 0-.08-.83A7.72 7.72 0 0 0 23 3z"></path>
</svg>
          </a>
        
      </div>
    </header>
    <main class="app-container">
      
  <article class="post">
    <header class="post-header">
      <h1 class ="post-title">记录一次照片文件的去重操作</h1>
      <div class="post-meta">
        <div>
          <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-calendar">
  <title>calendar</title>
  <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect><line x1="16" y1="2" x2="16" y2="6"></line><line x1="8" y1="2" x2="8" y2="6"></line><line x1="3" y1="10" x2="21" y2="10"></line>
</svg>
          May 24, 2024
        </div>
        <div>
          <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-clock">
  <title>clock</title>
  <circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline>
</svg>
          1 min read
        </div>
        <div>
          <svg viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="icon icon-tag">
  <title>tag</title>
  <path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7.01" y2="7"></line>
</svg>
              <a class="tag" href="https://ruohai.wang/tags/%E7%94%9F%E6%B4%BB/">生活</a>
        </div>
      </div>
    </header>
    <div class="post-content">
      <p>最近因为频繁的刷机 &amp; 部署photoprism，导致有一个盘上已经按照photoprism的入库规则统一重命名 &amp; 归档的400张照片忘记全部备份到群晖，然后又二次误操作把这几百张照片导入了新部署的photoprism。</p>
<p>这时候就出现了一个重复文件的问题：</p>
<ol>
<li>这400张照片，一部分已经备份到群晖，一部分没有。备份用的是rsync整个目录增量备份。</li>
<li>新部署的photoprism中，已经有100多张新照片，这次又二次导入了400张老照片，是新旧混杂的状态。</li>
<li>导入photoprism的照片，都会按照<code>yyyyMMdd-hhmmss-xxxxxx</code>这种<code>年月日-时分秒-随机六位字符</code>的格式作为唯一编号进行重命名，也就意味着这几百张二次导入的照片，文件名应该都发生了变化，变成了<code>新文件</code>，再用rsync增量备份的时候应该都会备当作新文件重复备份到群晖。</li>
</ol>
<p>作为有轻微电子洁癖的我肯定受不了这种nas里出现几百张重复照片的事情，所以立刻想着怎么去重。</p>
<p>当时想到的有两个方案：</p>
<ol>
<li>先全部备份到群晖，然后用群晖的重复文件检验功能筛选出重复文件的清单，最后手动清理群晖中的重复文件</li>
<li>使用第三方去重软件，比如<code>alldup</code></li>
</ol>
<p>这俩方法可行性都挺高的，虽然都略微繁琐，但最后肯定能实现去重的目的。</p>
<p>不过这俩方法我都没有用。因为前者需要把文件导入到群晖后，在群晖里操作。群晖里有我这十多年来的接近10万份个人文件，我担心在群晖里把文件弄乱，那就彻底gg。后者alldup支持smb网络文件夹，但是会把需要校验的文件都缓存到本地来计算hash。</p>
<p>因为我手上万幸还保留着那400张老照片，简单记录一下我的处理思路：</p>
<ul>
<li>去重的核心是<code>只修改文件名不会让文件的hash发生变化</code></li>
<li>先把400张老照片全量备份到群晖，解决这些老照片<strong>部分已备份 + 部分未备份</strong>的问题</li>
<li>接下去只需要比对photoprism图库中的全部照片 vs 400张老照片</li>
<li>在部署photoprism的armbian盒子上，用<code>sha256sum</code>获取到所有新文件和旧文件的hash值 + 文件名的清单</li>
<li>将上一步得到的清单粘贴到excel，用<code>vlookup</code>筛选出重复文件，以及这些重复文件的新文件名</li>
<li>写一个超级简单的bash脚本，直接将新重复的新文件从photoprism中删除</li>
<li>在photoprism中对资料库进行清理，将已经删除的文件清除索引</li>
</ul>
<p><img src="https://img.311803.xyz/2024/05/24/01.webp" alt=""></p>
<p>最后方便 &amp; 快速的完成了文件去重而且0误伤。🎉</p>
<p>这个方案的好处是</p>
<ol>
<li>不在群晖里操作，避免搞乱群晖的文件</li>
<li>在linux操作的命令也很简单，只需要进入照片目录，执行<code>sha256sum * &gt; hush.log</code>就可以获取到全部的<code>hash filename</code>格式的文本清单。</li>
<li>比对和筛选重复文件时在excel中用<code>vlookup</code>来完成，非常简单易懂直观</li>
<li>获取到最终要删除的文件名清单以后，只需要写一个很简单的bash脚本就可以批量删除文件</li>
</ol>
<p>bash脚本如下：</p>
<p><img src="https://img.311803.xyz/2024/05/24/02.webp" alt=""></p>
<p>最后，本次操作还发现一个新知识点：<strong>photoprism在归档照片的时候，如果照片的exif完整，包含拍摄时间这个参数，那生成的新文件名是固定的</strong>。</p>
<p>之前我一直以为photoprism的文件名规则中最后六位字符是随机字符，实测不是的，是固定值。</p>

    </div>
    <div class="post-footer">
      
    </div>
  </article>

    </main>
  </body>
</html>
